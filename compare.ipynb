{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaOI0qhdZo41YeOef5HE+q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LianBiao123/Myself-LB/blob/master/compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_tlCLgxJwHLp",
        "outputId": "c447d6d1-1513-4b7b-9d1a-44123128a1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install ftfy regex tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QovR2sgjwoar",
        "outputId": "c0f0159f-2c0f-4ca4-c50f-cc4d03fd9da5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-5pmii5g7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-5pmii5g7\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.2.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (3.0.3)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=83e5a2ccebc95b17634cf6b95d2a029500592598f0ad47cc592be47398913b9f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iq0m81ar/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import clip\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# 设置设备\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "01RIwemI0xX8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载CLIP模型\n",
        "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# 加载ResNet50模型\n",
        "resnet_model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "resnet_model.eval().to(device)\n",
        "\n",
        "# ResNet50预处理\n",
        "resnet_preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6x6bfSHA050Q",
        "outputId": "825b51a6-adf9-4c92-fe6e-fa14e8298e2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:06<00:00, 58.2MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载ImageNet类别文件\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\",\n",
        "    \"imagenet_classes.txt\"\n",
        ")\n",
        "\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    imagenet_classes = [s.strip() for s in f.readlines()]"
      ],
      "metadata": {
        "id": "N17V7mVy0-Vq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models_for_group(image_path, group_name, prompts_zh, prompts_en, imagenet_mapping):\n",
        "    \"\"\"\n",
        "    对比CLIP和ResNet50在特定实验组的表现\n",
        "\n",
        "    参数:\n",
        "    - image_path: 图片路径\n",
        "    - group_name: 实验组名称\n",
        "    - prompts_zh: 中文提示词列表\n",
        "    - prompts_en: 英文提示词列表\n",
        "    - imagenet_mapping: 到ImageNet类别的映射\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"实验组: {group_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # 加载图像\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        print(f\"成功加载图像: {image_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"无法加载图像: {image_path}, 错误: {e}\")\n",
        "        # 创建占位图像用于演示\n",
        "        image = Image.new('RGB', (224, 224), color='red')\n",
        "        print(\"使用占位图像继续演示\")\n",
        "\n",
        "    # CLIP预测\n",
        "    print(f\"\\n1. CLIP模型预测 (提示词: {prompts_zh})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    text = clip.tokenize(prompts_en).to(device)\n",
        "    image_input = clip_preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits_per_image, _ = clip_model(image_input, text)\n",
        "        clip_probs = logits_per_image.softmax(dim=-1).cpu().numpy()[0]\n",
        "\n",
        "    # 显示CLIP预测结果\n",
        "    clip_predictions = []\n",
        "    for i, prompt in enumerate(prompts_zh):\n",
        "        clip_predictions.append((prompt, clip_probs[i]))\n",
        "        print(f\"{prompt}: {clip_probs[i]:.4f}\")\n",
        "\n",
        "    # 找出CLIP的最佳预测\n",
        "    clip_best = max(clip_predictions, key=lambda x: x[1])\n",
        "    print(f\"CLIP最佳预测: '{clip_best[0]}' (概率: {clip_best[1]:.4f})\")\n",
        "\n",
        "    # ResNet50预测\n",
        "    print(f\"\\n2. ResNet50模型预测\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 预处理图像\n",
        "    image_input = resnet_preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = resnet_model(image_input)\n",
        "        probs = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "\n",
        "    # 获取ResNet50的Top-5预测\n",
        "    top5_probs, top5_indices = torch.topk(probs, 5)\n",
        "\n",
        "    print(\"ResNet50 Top-5预测:\")\n",
        "    resnet_top5 = []\n",
        "    for i in range(5):\n",
        "        class_name = imagenet_classes[top5_indices[i]]\n",
        "        probability = top5_probs[i].item()\n",
        "        resnet_top5.append((class_name, probability))\n",
        "        print(f\"  {i+1}. {class_name}: {probability:.4f}\")\n",
        "\n",
        "    # 尝试将提示词映射到ResNet50的预测\n",
        "    print(f\"\\n3. 提示词在ResNet50中的对应概率\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    resnet_prompt_probs = []\n",
        "    for prompt_zh, prompt_en in zip(prompts_zh, prompts_en):\n",
        "        mapped_label = imagenet_mapping.get(prompt_en, prompt_en)\n",
        "        if mapped_label in imagenet_classes:\n",
        "            idx = imagenet_classes.index(mapped_label)\n",
        "            probability = probs[idx].item()\n",
        "            resnet_prompt_probs.append((prompt_zh, probability))\n",
        "            print(f\"{prompt_zh} -> {mapped_label}: {probability:.4f}\")\n",
        "        else:\n",
        "            resnet_prompt_probs.append((prompt_zh, 0.0))\n",
        "            print(f\"{prompt_zh}: 在ImageNet中无对应类别\")\n",
        "\n",
        "    # 对比分析\n",
        "    print(f\"\\n4. 模型对比分析\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # CLIP的最佳预测\n",
        "    clip_best_prompt, clip_best_prob = clip_best\n",
        "\n",
        "    # 在ResNet50中找到对应提示词的最高概率\n",
        "    if resnet_prompt_probs:\n",
        "        resnet_best_prompt, resnet_best_prob = max(resnet_prompt_probs, key=lambda x: x[1])\n",
        "\n",
        "        print(f\"CLIP最佳预测: '{clip_best_prompt}' (概率: {clip_best_prob:.4f})\")\n",
        "        print(f\"ResNet50对应最佳: '{resnet_best_prompt}' (概率: {resnet_best_prob:.4f})\")\n",
        "\n",
        "        if resnet_best_prob > 0.01:  # 如果ResNet50有较确定的预测\n",
        "            if clip_best_prompt == resnet_best_prompt:\n",
        "                print(\"✓ 两个模型预测一致\")\n",
        "            else:\n",
        "                print(\"✗ 两个模型预测不一致\")\n",
        "\n",
        "            # 计算置信度差异\n",
        "            conf_diff = abs(clip_best_prob - resnet_best_prob)\n",
        "            print(f\"置信度差异: {conf_diff:.4f}\")\n",
        "        else:\n",
        "            print(\"ResNet50无法有效识别该类别\")\n",
        "\n",
        "        # 实验目的验证\n",
        "        if \"已知领域\" in group_name or \"组1\" in group_name:\n",
        "            if clip_best_prob > 0.7 and resnet_best_prob > 0.7:\n",
        "                print(\"✓ 验证结果: 在已知领域CLIP能达到CNN水平\")\n",
        "            else:\n",
        "                print(\"✗ 验证结果: 在已知领域CLIP未能达到CNN水平\")\n",
        "\n",
        "        elif \"未训练物体\" in group_name or \"组2\" in group_name:\n",
        "            if resnet_best_prob < 0.1:\n",
        "                print(\"✓ 验证结果: CNN对未训练物体直接失效\")\n",
        "            else:\n",
        "                print(\"✗ 验证结果: CNN对未训练物体仍有一定识别能力\")\n",
        "\n",
        "        elif \"抽象概念\" in group_name or \"组3\" in group_name:\n",
        "            if resnet_best_prob < 0.05:\n",
        "                print(\"✓ 验证结果: CNN完全无法处理抽象概念\")\n",
        "            else:\n",
        "                print(\"✗ 验证结果: CNN对抽象概念有一定识别能力\")\n",
        "\n",
        "        elif \"跨域数据\" in group_name or \"组4\" in group_name:\n",
        "            if resnet_best_prob < 0.1:\n",
        "                print(\"✓ 验证结果: CNN对跨域数据鲁棒性差\")\n",
        "            else:\n",
        "                print(\"✗ 验证结果: CNN对跨域数据有一定鲁棒性\")\n",
        "    else:\n",
        "        print(\"ResNet50无法识别任何指定类别\")\n",
        "\n",
        "    return {\n",
        "        \"group\": group_name,\n",
        "        \"clip_best\": clip_best,\n",
        "        \"resnet_best\": resnet_prompt_probs[0] if resnet_prompt_probs else (\"未知\", 0.0),\n",
        "        \"resnet_top5\": resnet_top5\n",
        "    }"
      ],
      "metadata": {
        "id": "o8CXJHcr65OB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 主函数 - 运行四组实验\n",
        "def run_all_experiments():\n",
        "    \"\"\"运行四组对比实验\"\"\"\n",
        "    print(\"CLIP vs ResNet50 四组对比实验\")\n",
        "    print(\"基于实验设计表格的完整对比\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 定义四组实验的参数\n",
        "    experiments = [\n",
        "        {\n",
        "            \"name\": \"组1 - ResNet见过的类别\",\n",
        "            \"image_path\": \"/golden_retriever.jpg\",  # 请替换为实际图片路径\n",
        "            \"prompts_zh\": [\"金毛犬\", \"波斯猫\", \"客机\"],\n",
        "            \"prompts_en\": [\"golden retriever\", \"Persian cat\", \"airliner\"],\n",
        "            \"imagenet_mapping\": {\n",
        "                \"golden retriever\": \"golden retriever\",\n",
        "                \"Persian cat\": \"Persian cat\",\n",
        "                \"airliner\": \"airliner\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"组2 - ResNet未见的物体\",\n",
        "            \"image_path\": \"/red_envelope.jpg\",  # 请替换为实际图片路径\n",
        "            \"prompts_zh\": [\"红包\", \"二维码\", \"麻将牌\"],\n",
        "            \"prompts_en\": [\"red envelope\", \"QR code\", \"mahjong tile\"],\n",
        "            \"imagenet_mapping\": {\n",
        "                \"red envelope\": \"piggy bank\",  # 近似映射\n",
        "                \"QR code\": \"modem\",  # 近似映射\n",
        "                \"mahjong tile\": \"domino\"  # 近似映射\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"组3 - ResNet未见抽象概念\",\n",
        "            \"image_path\": \"/new_year_atmosphere.jpg\",  # 请替换为实际图片路径\n",
        "            \"prompts_zh\": [\"喜庆氛围\", \"商业促销\", \"年味\"],\n",
        "            \"prompts_en\": [\"festive atmosphere\", \"commercial promotion\", \"new year atmosphere\"],\n",
        "            \"imagenet_mapping\": {\n",
        "                \"festive atmosphere\": \"fireworks\",  # 近似映射\n",
        "                \"commercial promotion\": \"shop\",  # 近似映射\n",
        "                \"new year atmosphere\": \"lantern\"  # 近似映射\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"组4 - 跨域数据（漫画/水彩）\",\n",
        "            \"image_path\": \"/cartoon_red_envelope.png\",  # 请替换为实际图片路径\n",
        "            \"prompts_zh\": [\"漫画红包\", \"水彩春节\", \"卡通年兽\"],\n",
        "            \"prompts_en\": [\"comic red envelope\", \"watercolor spring festival\", \"cartoon new year beast\"],\n",
        "            \"imagenet_mapping\": {\n",
        "                \"comic red envelope\": \"comic book\",  # 近似映射\n",
        "                \"watercolor spring festival\": \"watercolor\",  # 近似映射\n",
        "                \"cartoon new year beast\": \"cartoon\"  # 近似映射\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 运行每组实验\n",
        "    for exp in experiments:\n",
        "        result = compare_models_for_group(\n",
        "            exp[\"image_path\"],\n",
        "            exp[\"name\"],\n",
        "            exp[\"prompts_zh\"],\n",
        "            exp[\"prompts_en\"],\n",
        "            exp[\"imagenet_mapping\"]\n",
        "        )\n",
        "        results.append(result)\n",
        "\n",
        "    # 总结所有实验结果\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"实验总结\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    for result in results:\n",
        "        group = result[\"group\"]\n",
        "        clip_best = result[\"clip_best\"]\n",
        "        resnet_best = result[\"resnet_best\"]\n",
        "\n",
        "        print(f\"\\n{group}:\")\n",
        "        print(f\"  CLIP最佳预测: {clip_best[0]} (概率: {clip_best[1]:.4f})\")\n",
        "        print(f\"  ResNet50最佳对应: {resnet_best[0]} (概率: {resnet_best[1]:.4f})\")\n",
        "\n",
        "        # 判断模型表现\n",
        "        if resnet_best[1] > 0.5:\n",
        "            print(\"  ResNet50表现: 良好\")\n",
        "        elif resnet_best[1] > 0.1:\n",
        "            print(\"  ResNet50表现: 一般\")\n",
        "        else:\n",
        "            print(\"  ResNet50表现: 较差\")\n",
        "\n",
        "        if clip_best[1] > 0.5:\n",
        "            print(\"  CLIP表现: 良好\")\n",
        "        elif clip_best[1] > 0.1:\n",
        "            print(\"  CLIP表现: 一般\")\n",
        "        else:\n",
        "            print(\"  CLIP表现: 较差\")\n",
        "if __name__ == \"__main__\":\n",
        "    run_all_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fUeKbXC7yMj",
        "outputId": "fd8e8d34-6bbf-4d9a-f172-669578b2e975"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP vs ResNet50 四组对比实验\n",
            "基于实验设计表格的完整对比\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "实验组: 组1 - ResNet见过的类别\n",
            "============================================================\n",
            "成功加载图像: /golden_retriever.jpg\n",
            "\n",
            "1. CLIP模型预测 (提示词: ['金毛犬', '波斯猫', '客机'])\n",
            "--------------------------------------------------\n",
            "金毛犬: 1.0000\n",
            "波斯猫: 0.0000\n",
            "客机: 0.0000\n",
            "CLIP最佳预测: '金毛犬' (概率: 1.0000)\n",
            "\n",
            "2. ResNet50模型预测\n",
            "--------------------------------------------------\n",
            "ResNet50 Top-5预测:\n",
            "  1. golden retriever: 0.9110\n",
            "  2. Labrador retriever: 0.0169\n",
            "  3. Pembroke: 0.0070\n",
            "  4. tennis ball: 0.0039\n",
            "  5. Leonberg: 0.0038\n",
            "\n",
            "3. 提示词在ResNet50中的对应概率\n",
            "--------------------------------------------------\n",
            "金毛犬 -> golden retriever: 0.9110\n",
            "波斯猫 -> Persian cat: 0.0000\n",
            "客机 -> airliner: 0.0000\n",
            "\n",
            "4. 模型对比分析\n",
            "--------------------------------------------------\n",
            "CLIP最佳预测: '金毛犬' (概率: 1.0000)\n",
            "ResNet50对应最佳: '金毛犬' (概率: 0.9110)\n",
            "✓ 两个模型预测一致\n",
            "置信度差异: 0.0890\n",
            "✓ 验证结果: 在已知领域CLIP能达到CNN水平\n",
            "\n",
            "============================================================\n",
            "实验组: 组2 - ResNet未见的物体\n",
            "============================================================\n",
            "成功加载图像: /red_envelope.jpg\n",
            "\n",
            "1. CLIP模型预测 (提示词: ['红包', '二维码', '麻将牌'])\n",
            "--------------------------------------------------\n",
            "红包: 1.0000\n",
            "二维码: 0.0000\n",
            "麻将牌: 0.0000\n",
            "CLIP最佳预测: '红包' (概率: 1.0000)\n",
            "\n",
            "2. ResNet50模型预测\n",
            "--------------------------------------------------\n",
            "ResNet50 Top-5预测:\n",
            "  1. envelope: 0.9194\n",
            "  2. packet: 0.0441\n",
            "  3. wallet: 0.0091\n",
            "  4. Windsor tie: 0.0042\n",
            "  5. handkerchief: 0.0041\n",
            "\n",
            "3. 提示词在ResNet50中的对应概率\n",
            "--------------------------------------------------\n",
            "红包 -> piggy bank: 0.0000\n",
            "二维码 -> modem: 0.0000\n",
            "麻将牌: 在ImageNet中无对应类别\n",
            "\n",
            "4. 模型对比分析\n",
            "--------------------------------------------------\n",
            "CLIP最佳预测: '红包' (概率: 1.0000)\n",
            "ResNet50对应最佳: '红包' (概率: 0.0000)\n",
            "ResNet50无法有效识别该类别\n",
            "✓ 验证结果: CNN对未训练物体直接失效\n",
            "\n",
            "============================================================\n",
            "实验组: 组3 - ResNet未见抽象概念\n",
            "============================================================\n",
            "成功加载图像: /new_year_atmosphere.jpg\n",
            "\n",
            "1. CLIP模型预测 (提示词: ['喜庆氛围', '商业促销', '年味'])\n",
            "--------------------------------------------------\n",
            "喜庆氛围: 0.7878\n",
            "商业促销: 0.0675\n",
            "年味: 0.1448\n",
            "CLIP最佳预测: '喜庆氛围' (概率: 0.7878)\n",
            "\n",
            "2. ResNet50模型预测\n",
            "--------------------------------------------------\n",
            "ResNet50 Top-5预测:\n",
            "  1. confectionery: 0.5205\n",
            "  2. grocery store: 0.1719\n",
            "  3. bakery: 0.0420\n",
            "  4. toyshop: 0.0407\n",
            "  5. tray: 0.0399\n",
            "\n",
            "3. 提示词在ResNet50中的对应概率\n",
            "--------------------------------------------------\n",
            "喜庆氛围: 在ImageNet中无对应类别\n",
            "商业促销: 在ImageNet中无对应类别\n",
            "年味: 在ImageNet中无对应类别\n",
            "\n",
            "4. 模型对比分析\n",
            "--------------------------------------------------\n",
            "CLIP最佳预测: '喜庆氛围' (概率: 0.7878)\n",
            "ResNet50对应最佳: '喜庆氛围' (概率: 0.0000)\n",
            "ResNet50无法有效识别该类别\n",
            "✓ 验证结果: CNN完全无法处理抽象概念\n",
            "\n",
            "============================================================\n",
            "实验组: 组4 - 跨域数据（漫画/水彩）\n",
            "============================================================\n",
            "成功加载图像: /cartoon_red_envelope.png\n",
            "\n",
            "1. CLIP模型预测 (提示词: ['漫画红包', '水彩春节', '卡通年兽'])\n",
            "--------------------------------------------------\n",
            "漫画红包: 0.9945\n",
            "水彩春节: 0.0041\n",
            "卡通年兽: 0.0014\n",
            "CLIP最佳预测: '漫画红包' (概率: 0.9945)\n",
            "\n",
            "2. ResNet50模型预测\n",
            "--------------------------------------------------\n",
            "ResNet50 Top-5预测:\n",
            "  1. gas pump: 0.4768\n",
            "  2. perfume: 0.0753\n",
            "  3. lighter: 0.0669\n",
            "  4. scale: 0.0378\n",
            "  5. digital clock: 0.0361\n",
            "\n",
            "3. 提示词在ResNet50中的对应概率\n",
            "--------------------------------------------------\n",
            "漫画红包 -> comic book: 0.0002\n",
            "水彩春节: 在ImageNet中无对应类别\n",
            "卡通年兽: 在ImageNet中无对应类别\n",
            "\n",
            "4. 模型对比分析\n",
            "--------------------------------------------------\n",
            "CLIP最佳预测: '漫画红包' (概率: 0.9945)\n",
            "ResNet50对应最佳: '漫画红包' (概率: 0.0002)\n",
            "ResNet50无法有效识别该类别\n",
            "✓ 验证结果: CNN对跨域数据鲁棒性差\n",
            "\n",
            "============================================================\n",
            "实验总结\n",
            "============================================================\n",
            "\n",
            "组1 - ResNet见过的类别:\n",
            "  CLIP最佳预测: 金毛犬 (概率: 1.0000)\n",
            "  ResNet50最佳对应: 金毛犬 (概率: 0.9110)\n",
            "  ResNet50表现: 良好\n",
            "  CLIP表现: 良好\n",
            "\n",
            "组2 - ResNet未见的物体:\n",
            "  CLIP最佳预测: 红包 (概率: 1.0000)\n",
            "  ResNet50最佳对应: 红包 (概率: 0.0000)\n",
            "  ResNet50表现: 较差\n",
            "  CLIP表现: 良好\n",
            "\n",
            "组3 - ResNet未见抽象概念:\n",
            "  CLIP最佳预测: 喜庆氛围 (概率: 0.7878)\n",
            "  ResNet50最佳对应: 喜庆氛围 (概率: 0.0000)\n",
            "  ResNet50表现: 较差\n",
            "  CLIP表现: 良好\n",
            "\n",
            "组4 - 跨域数据（漫画/水彩）:\n",
            "  CLIP最佳预测: 漫画红包 (概率: 0.9945)\n",
            "  ResNet50最佳对应: 漫画红包 (概率: 0.0002)\n",
            "  ResNet50表现: 较差\n",
            "  CLIP表现: 良好\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52O86XBm70Gi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}